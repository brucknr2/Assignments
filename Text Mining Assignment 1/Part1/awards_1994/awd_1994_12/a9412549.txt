Title       : Using Parallelism to Scale Up Machine Learning to Large Data-Analysis Problems
Type        : Award
NSF Org     : IIS 
Latest
Amendment
Date        : February 3,  1997   
File        : a9412549

Award Number: 9412549
Award Instr.: Continuing grant                             
Prgm Manager: Larry H. Reeker                         
	      IIS  DIV OF INFORMATION & INTELLIGENT SYSTEMS
	      CSE  DIRECT FOR COMPUTER & INFO SCIE & ENGINR
Start Date  : April 1,  1995      
Expires     : March 31,  1998      (Estimated)
Expected
Total Amt.  : $240101             (Estimated)
Investigator: Bruce G. Buchanan buchanan@cs.pitt.edu  (Principal Investigator current)
              John M. Aronis  (Co-Principal Investigator current)
              Foster J. Provost  (Co-Principal Investigator current)
Sponsor     : U of Pittsburgh
	      4200 Fifth Avenue
	      Pittsburgh, PA  152600001    412/624-4141

NSF Program : 6856      KNOWLEDGE & COGNITIVE SYSTEMS
Fld Applictn: 0104000   Information Systems                     
              99        Other Sciences NEC                      
Program Ref : 2891,9139,HPCC,
Abstract    :
              IRI-9412205  Etherington, David  University of Oregon Eugene  $62,828 - 12 mos. 
                Toward Efficient Default Reasoning          This is the first year finding of
              a research project involving  a three year study of a novel
              approximation-based, approach to  tractable nonmonotonic reasoning. 
              Nonmonotonicity is a critical  part of most human reasoning tasks.  Despite
              this, current  nonmonotonic reasoning formalisms are inherently undecidable in
              the  general case, and are intractable in all but the most restrictive  cases. 
              To address this intractability, two known, weak,  techniques-context-limited
              reasoning and fast, incomplete  consistency testing-will be combined to develop
              a powerful,  tractable, approximation mechanism.         Neither of these
              techniques, alone, suffices, however.  Since  consistency is undecidable in the
              first-order case, context limited  reasoning does not, by itself, guarantee
              tractability, Furthermore,  known fast, incomplete consistency tests generally
              fail in  realistically-complex knowledge bases.  The goal of this research  is
              the show that the combination of the two techniques  synergistically yields a
              tractable approximate nonmonotonic  reasoning mechanism that overcomes the
              limitations of either  technique alone.         The conditions under which this
              approach gives justifiable  results will be formalized, and probabilistic
              arguments will be  developed showing that the approximations induced are
              reasonable  for certain useful types of default reasoning.  Formal results will
               be proved showing that the approximations converge to fully-correct  reasoning
              as additional computational resources are expended.  The  mechanisms necessary
              for building and maintaining contexts and for  dealing with the errors induced
              by the approximation will then be  studied.  Finally, these ideas will be
              implemented and evaluated  empirically against non-trivial knowledge bases.
