Title       : CISE Research Instrumentation: High-Performance Vehicle with Visual and Deictic
               Control
Type        : Award
NSF Org     : EIA 
Latest
Amendment
Date        : April 6,  1995      
File        : a9421532

Award Number: 9421532
Award Instr.: Standard Grant                               
Prgm Manager: Tuz C. Ting                             
	      EIA  DIVISION OF EXPERIMENTAL & INTEG ACTIVIT
	      CSE  DIRECT FOR COMPUTER & INFO SCIE & ENGINR
Start Date  : May 1,  1995        
Expires     : April 30,  1996      (Estimated)
Expected
Total Amt.  : $17100              (Estimated)
Investigator: Randal C. Nelson nelson@cs.rochester.edu  (Principal Investigator current)
              Roger F. Gans  (Co-Principal Investigator current)
              Christopher M. Brown  (Co-Principal Investigator current)
Sponsor     : University of Rochester
	      
	      Rochester, NY  14627    585/275-4031

NSF Program : 2890      CISE INSTRUMENTATION
Fld Applictn: 0000099   Other Applications NEC                  
              31        Computer Science & Engineering          
Program Ref : 9218,HPCC,
Abstract    :
              9421532  Nelson     This award is to support the research effort for the
              University of Rochester's Computer Science and Mechanical Engineering
              Departments to build and control a pair of small, off-road vehicles; one
              human-piloted, and one computer-controlled.  Intrinsically interesting aspects
              of the equipment are low cost, off-road capability, and relatively high speeds
              (50 kph).  The two vehicles will support research on semi-autonomous control,
              real-time visual processing, real-time decision-making, control learning, and
              simulation.     The research issues center around semi-autonomous or "deictic"
              control in which visual or symbolic commands are passed to the
              computer-controlled vehicle for local interpretation.  This control style is
              increasingly popular for difficult, real-time control tasks (e.g.
              telemanipulation) in which neither full autonomy, nor direct teleoperation is
              feasible.  Rochester will continue working on this topic.     Deictic control
              does not solve all control problems: control learning can play an important
              role.  Two aspects of control learning will be investigated: learning tunable
              "motor skills" necessary to cope with high-speed situations, and, at a higher
              level, learning sequences of appropriate actions.  Both types of learning are
              already under investigation at Rochester.  Today's learning algorithms often
              receive initial training in simulation, so sophisticated simulation work
              already underway will be used.  ***
