Title       : RIA: Variable Resolution Reinforcement Learning
Type        : Award
NSF Org     : IIS 
Latest
Amendment
Date        : February 7,  1997   
File        : a9409912

Award Number: 9409912
Award Instr.: Continuing grant                             
Prgm Manager: Larry H. Reeker                         
	      IIS  DIV OF INFORMATION & INTELLIGENT SYSTEMS
	      CSE  DIRECT FOR COMPUTER & INFO SCIE & ENGINR
Start Date  : September 1,  1994  
Expires     : August 31,  1997     (Estimated)
Expected
Total Amt.  : $95872              (Estimated)
Investigator: Andrew W. Moore awm@cs.cmu.edu  (Principal Investigator current)
Sponsor     : Carnegie Mellon University
	      5000 Forbes Avenue
	      Pittsburgh, PA  152133815    412/268-5835

NSF Program : 6856      KNOWLEDGE & COGNITIVE SYSTEMS
Fld Applictn: 0104000   Information Systems                     
              99        Other Sciences NEC                      
Program Ref : 9216,9264,HPCC,
Abstract    :
              9409912  Moore       Reinforcement learning is a promising method for robots and
               other complex autonomous systems to program and improve themselves.   It
              requires no fixed, pre-programmed decision routines and no pre-  programmed
              system model.  Its high degree of autonomy comes at a  severe price:  the curse
              of dimensionality, in which costs increase  exponentially with the number of
              state variables.  The proposed  research will address this problem by
              adaptively partitioning the  state space of the system into homogenous regions
              while the system  is learning.  Unimportant or unvarying regions are always 
              represented by large partitions whilst critical regions or  important problem
              features emerge as finely partitioned areas.  The  algorithms take advantage of
              two surprisingly powerful assumptions  which are frequently true in problems
              with multivariate real-valued  state spaces.  First, that all possible paths
              through state space  are continuous, and secondly that high quality execution
              of a task  does not require perfect knowledge of the whole of state space.  An 
              important part of the proposal concerns the development of a suite  of cheap
              robotic experiments, carefully designed to involve a wide  variety of
              interesting non-linear problems.  A learning algorithm  which could learn many
              different real-world tasks automatically  would be academically interesting and
              also have industrial impact.
