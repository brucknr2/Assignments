Title       : RUI: The Analysis of 3-D Motion for Visually-Guided Navigation
Type        : Award
NSF Org     : BCS 
Latest
Amendment
Date        : November 18,  1998  
File        : a9301326

Award Number: 9301326
Award Instr.: Continuing grant                             
Prgm Manager: Helene Intraub                          
	      BCS  DIVISION OF BEHAVIORAL AND COGNITIVE SCI
	      SBE  DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE
Start Date  : June 1,  1994       
Expires     : August 31,  1998     (Estimated)
Expected
Total Amt.  : $233788             (Estimated)
Investigator: Ellen C. Hildreth EHildreth@Lucy.wellesley.edu  (Principal Investigator current)
              Constance S. Royden  (Co-Principal Investigator current)
Sponsor     : Wellesley College
	      
	      Wellesley, MA  02481    617/235-0320

NSF Program : 1180      HUMAN COGNITION & PERCEPTION
Fld Applictn: 0000099   Other Applications NEC                  
              71        Psychology Biological Aspects           
Program Ref : 0000,9218,HPCC,OTHR,
Abstract    :
              9301326  HILDRETH    When an observer moves through the environment, a
              continually  changing visual image appears on the surface of the eye.  The 
              motion of features in this image conveys information about the  direction and
              speed of movement of the observer through space, as  well as about the
              three-dimensional motion of other objects in the  environment.  It is known
              that from image motion alone, human  observers can judge their 3-D direction of
              translation relative to  a stationary scene with high accuracy.  The recovery
              of the  observer's movement from image motion becomes far more challenging 
              when the environment contains objects that undergo their own motion  through
              space.  This research will investigate the mechanisms by  which the human
              visual system analyzes the motions of the observer  and objects in the
              environment from information available in the  changing visual image. 
              Psychophysical experiments will examine the  accuracy with which humans judge
              their 3-D direction of translation  when viewing dynamic visual displays that
              simulate the motion of an  observer toward a scene containing moving objects. 
              Further  experiments will test the human ability to detect moving objects, 
              measure their 3-D direction of translation relative to the  observer, and judge
              the time-to-collision of the observer with  approaching objects.  The
              successful navigation of human observers  through complex dynamic scenes
              requires that these tasks be  performed with high accuracy.  Computational
              models will be  developed that capture the behavior observed in these
              experiments.   These models will be implemented and tested in a computer vision
               system that recovers the 3-D motion of a mobile camera and moving  objects
              from a sequence of digitized 2-D images.    The results of this work will
              further our knowledge of how the  human system uses the analysis of image
              motion to perform tasks  such as navigation through complex scenes.  They will
              also  contribute to the development of successful computer vision sys tems  for
              autonomous navigation and to applications requiring the  interpretation of 3-D
              motion and structure from dynamic imagery in  domains such as robotics, medical
              imaging, and surveillance.    ***
