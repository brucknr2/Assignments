Title       : Improved Statistical Language Models
Type        : Award
NSF Org     : IIS 
Latest
Amendment
Date        : March 4,  1998      
File        : a9319516

Award Number: 9319516
Award Instr.: Continuing grant                             
Prgm Manager: Gary W Strong                           
	      IIS  DIV OF INFORMATION & INTELLIGENT SYSTEMS
	      CSE  DIRECT FOR COMPUTER & INFO SCIE & ENGINR
Start Date  : September 1,  1994  
Expires     : August 31,  1998     (Estimated)
Expected
Total Amt.  : $241263             (Estimated)
Investigator: Eugene Charniak ec@bohr.cs.brown.edu  (Principal Investigator current)
Sponsor     : Brown University
	      164 Angell Street
	      Providence, RI  02912    401/863-2777

NSF Program : 6845      HUMAN COMPUTER INTER PROGRAM
Fld Applictn: 0104000   Information Systems                     
              99        Other Sciences NEC                      
Program Ref : 9218,HPCC,
Abstract    :
                         9319516  Charniak    This is the first-year award of a three-year
              continuing grant to  study the use of probabilities and probabilistic language
              models in  context-free parsing applications.  The research consists of four 
              parts: 1) use of probabilities in the syntactic parsing of English  through
              automatic generation of a probabilistic grammar by applying  standard
              statistical techniques to corpora that has been hand-  tagged; 2) a portion of
              the resources in the statistical analysis  involves the co-occurrence of words,
              which improves the  effectiveness of the language model thereby helping the 
              determination in the parse that, for example, a noun would be more  likely in a
              certain position than another, rather than just the  parts-of-speech results
              that would be obtained via a classical  parser; 3) it is anticipated that some
              level of semantic  generalization may be possible by grouping the words with
              similar  statistics in classes, as statistical parameters are smoothed; and 
              finally, 4) the model obtained and smoothed is rigorously tested  through an
              objective quality measure such as the per-word cross  entropy.  The goal is to
              improve upon existing trigram models,  currently in use in speech recognition,
              and to work towards better  language understanding systems.
