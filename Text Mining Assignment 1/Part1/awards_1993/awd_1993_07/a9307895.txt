Title       : Testing and Exploiting Clustering for Data Compression
Type        : Award
NSF Org     : IIS 
Latest
Amendment
Date        : June 7,  1995       
File        : a9307895

Award Number: 9307895
Award Instr.: Continuing grant                             
Prgm Manager:                                         
	      IIS  DIV OF INFORMATION & INTELLIGENT SYSTEMS
	      CSE  DIRECT FOR COMPUTER & INFO SCIE & ENGINR
Start Date  : August 1,  1993     
Expires     : December 31,  1996   (Estimated)
Expected
Total Amt.  : $122929             (Estimated)
Investigator: Abraham Bookstein   (Principal Investigator current)
Sponsor     : University of Chicago
	      5801 South Ellis Avenue
	      Chicago, IL  606371404    773/702-8602

NSF Program : 6855      INFORMATION & DATA MANAGEMENT
Fld Applictn: 0104000   Information Systems                     
              99        Other Sciences NEC                      
Program Ref : 6855,9216,HPCC,
Abstract    :
                9307895  Bookstein    Testing and Exploiting Clustering for Data Compression  
               This is the first year funding of a three-year continuing award.   This
              project develops techniques for compressing concordances of  large, full-text
              databases.  The practical significance is obvious,  since concordances are
              huge, consuming as much resources as the  data themselves; yet they are
              necessary to access the database  efficiently.  But the theoretical
              implications are also important,  since the highly structured organization of
              concordances makes them  suitable for modeling.  In this project clustering in
              concordances  is modeled.  Sequential clustering is important in Information 
              Retrieval generally: substantive terms tend to occur together in a  document,
              and documents containing a given term often cluster in a  typical database. 
              This project develops and evaluates statistical  tests that indicate when
              clustering is important; identifies  measures of sequential clustering
              strength; and creates models of  concordance generation recognizing clustering,
              improving  compression effectiveness.  The models studied include Markov 
              models and Bayesian learning models.  Sequential clustering is  widespread and
              the results of this research should have  implications well beyond data
              compression, for example analyzing  term occurrence to identify content bearing
              terms for retrieval  purposes.  Thus this project promises direct benefits in
              improving  our ability to store very large textual databases and, indirectly, 
              in developing methodology of wider interest.   ***
