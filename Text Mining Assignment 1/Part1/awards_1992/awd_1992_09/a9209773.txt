Title       : Recovery of Viewer-Centered and Object-Centered Depth from 2-D Projections
Type        : Award
NSF Org     : BCS 
Latest
Amendment
Date        : June 14,  1994      
File        : a9209773

Award Number: 9209773
Award Instr.: Continuing grant                             
Prgm Manager: Joseph L. Young                         
	      BCS  DIVISION OF BEHAVIORAL AND COGNITIVE SCI
	      SBE  DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE
Start Date  : August 15,  1992    
Expires     : July 31,  1996       (Estimated)
Expected
Total Amt.  : $189138             (Estimated)
Investigator: Myron L. Braunstein   (Principal Investigator current)
Sponsor     : U of Cal Irvine
	      160 Administration Building
	      Irvine, CA  926971875    949/824-7106

NSF Program : 1180      HUMAN COGNITION & PERCEPTION
Fld Applictn: 0000099   Other Applications NEC                  
              71        Psychology Biological Aspects           
Program Ref : 0000,9251,OTHR,
Abstract    :
                                                                                             
              Perceiving the three-dimensional environment on the basis of the               
              two-dimensional images projected onto the retinas of the two eyes              
              requires integration of different sources of depth information.                
              This project will examine the integration of two types of depth                
              information, i.e., viewer-centered information, which provides                 
              relative distances between an observer and objects in the                      
              environment, and object-centered information, which provides                   
              relative distances within an external scene, independent of viewer             
              location.  The viewer-centered information that will be studied                
              will include binocular disparity (differences in the object's                  
              projection onto the retinas of the two eyes as a function of                   
              relative distances from the observer) and motion parallax                      
              (variations in the velocities projected onto the eye as a function             
              of distance from the observer).  The object-centered information of            
              primary interest is structure-from-motion (use of changing                     
              distances in the projection to recover distances between features              
              on a three-dimensional object, under an assumption of rigid                    
              motion).  One series of experiments will examine how the perceived             
              three-dimensional shapes of objects are determined by the                      
              partitioning of motion in the retinal images into viewer-centered              
              and object-centered components (motion parallax and structure-from-            
              motion).  A second series of experiments will examine integration              
              of shape recovered from object-centered information into a viewer-             
              centered representation of the three-dimensional environment.  A               
              third series of experiments will examine the changes in the                    
              perceived shapes and orientations of objects that occurs when                  
              information indicating lack of depth is added to a three-                      
              dimensional scene.  A fourth series of experiments will determine              
              the minimum number of visible features on an object needed to                  
              detect a surface from a combination of viewer-centered information             
              (binocular disparity) and object-centered information (structure-              
              from-motion).  The objective of this research is to understand how             
              different types of depth information are combined to provide an                
              integrated perception of the three-dimensional environment.  This              
              has relevance for such issues as optimizing human performance in               
              object recognition in actual three-dimensional environments and                
              designing artificial three-dimensional displays, including displays            
              for flight simulators and aircraft displays that represent the                 
              virtual environment.
