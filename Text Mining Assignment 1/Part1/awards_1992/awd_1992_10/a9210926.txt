Title       : Modeling and 3D Analysis of Multi Sensory Image Sequences and the Design of a
               Hybrid Range-Intensity Sequence Sensor
Type        : Award
NSF Org     : IIS 
Latest
Amendment
Date        : December 16,  1994  
File        : a9210926

Award Number: 9210926
Award Instr.: Continuing grant                             
Prgm Manager: Howard Moraff                           
	      IIS  DIV OF INFORMATION & INTELLIGENT SYSTEMS
	      CSE  DIRECT FOR COMPUTER & INFO SCIE & ENGINR
Start Date  : November 1,  1992   
Expires     : April 30,  1996      (Estimated)
Expected
Total Amt.  : $89657              (Estimated)
Investigator: Guna Seetharaman guna@cacs.usl.edu  (Principal Investigator current)
Sponsor     : Univ of Louisiana at Lafay
	      104 University Circle
	      Lafayette, LA  705032701    337/482-6203

NSF Program : 6840      ROBOTICS AND HUMAN AUGMENTATIO
Fld Applictn: 0104000   Information Systems                     
              99        Other Sciences NEC                      
Program Ref : 9216,9218,HPCC,
Abstract    :
              This research investigates the three dimensional (3D)                          
              perception of a dynamic scene from multisensory image sequences.               
              The results should greatly enhance the design and operation of                 
              intelligent robotic systems (IRS) capable of predicting,                       
              detecting and recovering from dynamic failures.  The objective is              
              to identify and locate each object present in the work-space of                
              the IRS over a vast dynamic range of 3-D scene conditions.  The                
              major problems occur due to:  i) self-occlusion of 3-D opaque                  
              objects; ii) inherent loss of depth (3-D) information introduced               
              by the video imaging process; iii) inevitability of secondary                  
              occlusions when there is more than one object in the scene.  Two               
              observations are necessary to counter self-occlusion and                       
              compensate the loss of depth information.  However, three images               
              are necessary to uniquely solve a similar set of nonlinear                     
              equations in 3-D motion analysis of a monocular image sequence.                
              Thus, the IRS must use three or more image sensors from                        
              distinctly different vantage (view) points.  The span of these                 
              vantage point is called the spatial aperture of the vision                     
              system.  A major bottleneck lies with the registration of images               
              over the spatial aperture.  It can be simplified by:  i)                       
              spatially fusing the temporal (dynamic) information contained in               
              each image sequences; ii) introducing additional constraints                   
              using a laser beam when option (ii) is not feasible.  A                        
              theoretical framework will be developed for bilateral propogation              
              of geometric constraints over the spatial aperture and temporal                
              window to enhance the operational capabilities of the vision                   
              system.  A hybrid range-intensity image sequence sensor has                    
              already been designed to provide a test environment required to                
              experimentally validate the results.
