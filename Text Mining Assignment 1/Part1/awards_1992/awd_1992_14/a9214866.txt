Title       : Reinforcement Learning Algorithms Based on Dynamic Programming
Type        : Award
NSF Org     : ECS 
Latest
Amendment
Date        : July 28,  1995      
File        : a9214866

Award Number: 9214866
Award Instr.: Continuing grant                             
Prgm Manager: Paul Werbos                             
	      ECS  DIV OF ELECTRICAL AND COMMUNICATIONS SYS
	      ENG  DIRECTORATE FOR ENGINEERING             
Start Date  : September 15,  1992 
Expires     : February 28,  1997   (Estimated)
Expected
Total Amt.  : $316309             (Estimated)
Investigator: Andrew G. Barto barto@cs.umass.edu  (Principal Investigator current)
              B. Erik Ydstie  (Co-Principal Investigator current)
Sponsor     : U of Massachusetts Amherst
	      408 Goodell Building
	      Amherst, MA  010033285    413/545-0698

NSF Program : 1518      CONTROL, NETWORKS, & COMP INTE
Fld Applictn: 0510403   Engineering & Computer Science          
              55        Engineering-Electrical                  
Program Ref : 0000,9216,HPCC,OTHR,
Abstract    :
              This project will investigate aspects of a                                     
              class of reinforcement learning                                                
              algorithms based on dynamic                                                    
              programming (DP).  Although these                                              
              algorithms have been widely studied and                                        
              have been experimented with in many                                            
              applications,   their theory is not                                            
              developed enough to permit a clear                                             
              understanding of the classes of problems                                       
              for which they may be the methods of                                           
              choice, or to guide their application.                                         
              Research at the University of                                                  
              Massachusetts has made considerable                                            
              recent progress in relating these                                              
              methods to the most closely related                                            
              conventional methods and in                                                    
              understanding the factors that influence                                       
              their performance, both successful and                                         
              unsuccessful.  These methods may                                               
              provide the only computationally                                               
              feasible approaches to very large and                                          
              analytically intractable sequential                                            
              decision problems. The objectives of this                                      
              project are:  1) to continue development                                       
              of DP-based reinforcement learning                                             
              methods an their theory, 2) to                                                 
              investigate their computational                                                
              complexity, and 3) to define the                                               
              characteristics of problems for which                                          
              they are best suited.
