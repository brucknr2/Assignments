Title       : Interactive Processes of Language Use in Human-Computer Interfaces
Type        : Award
NSF Org     : IIS 
Latest
Amendment
Date        : June 20,  1994      
File        : a9202458

Award Number: 9202458
Award Instr.: Continuing grant                             
Prgm Manager: Gary W Strong                           
	      IIS  DIV OF INFORMATION & INTELLIGENT SYSTEMS
	      CSE  DIRECT FOR COMPUTER & INFO SCIE & ENGINR
Start Date  : August 15,  1992    
Expires     : July 31,  1996       (Estimated)
Expected
Total Amt.  : $244888             (Estimated)
Investigator: Susan E. Brennan susan.brennan@sunysb.edu  (Principal Investigator current)
Sponsor     : SUNY Stony Brook
	      
	      Stony Brook, NY  117943362    631/632-9949

NSF Program : 6845      HUMAN COMPUTER INTER PROGRAM
Fld Applictn: 0104000   Information Systems                     
              99        Other Sciences NEC                      
Program Ref : 9216,HPCC,
Abstract    :
                  9202458  Brennan      This is the third year of a three-year continuing
              award.  The goal  of this research is to better understand the interactive
              process of  human language use with a computer system.  The theory underlying 
              this research is that human-computer interaction, like human  communication,
              falls into a class of coordinated actions that  proceeds by the systematic
              exchange of evidence of understanding.   Two processes are examined:  a)
              entrainment, which is hypothesized  to influence lexical choice, and b)
              grounding, which is  hypothesized to set the level and placement of appropriate
               feedback.  Psychological experiments will use simulated language  and voice
              interfaces to examine 1) what variables influence the  lexical choice people
              make and how such a system might adapt to  idiosyncratic language input, 2)
              what kind of text output should  the system generate to present itself as a
              coherent dialog partner,  and 3) what kinds of context-sensitive feedback
              should a speech or  language interface provide.  The goals are to contribute to
              the  design of adaptive user interfaces, to enable more robust error  handling,
              and to make natural language, command, and voice  interfaces easier for people
              to use.
